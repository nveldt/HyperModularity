{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Parameterized Affinity Functions\n",
    "\n",
    "In this notebook, we'll demonstrate how to define parameterized affinity functions and perform coordinate-ascent maximum-likelihoood inference to estimate their parameters. There are a few important limitations to keep in mind when doing this. \n",
    "\n",
    "1. As currently implemented, the parameter estimate step of coordinate ascent can be quite slow on graphs with more than a few hundred nodes. \n",
    "2. Additionally, because the node clustering step of coordinate ascent is implemented via Louvain, only affinity functions that encourage assortative cluster structure are likely to lead to interpretable results. \n",
    "\n",
    "Because of these limitations, general parameterized affinity functions are not used in the paper  \n",
    "\n",
    "> Chodrow, Philip S., Nate Veldt, and Austin R. Benson. \"Generative hypergraph clustering: from blockmodels to modularity.\" arXiv preprint arXiv:2101.09611 (2021).\n",
    "\n",
    "With this in mind, this feature should be regarded as experimental. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: no Manifest.toml file found, static paths used\n",
      "└ @ Revise /home/phil/.julia/packages/Revise/BqeJF/src/Revise.jl:1328\n",
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/HyperModularity/Project.toml`\n",
      "┌ Info: Precompiling HyperModularity [bc4352e7-2825-48c1-aa5c-95462f20dcc0]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Pkg; Pkg.activate(\"../.\")\n",
    "using HyperModularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, an affinity function $\\Omega$ is defined by a function $\\omega(p, \\alpha)$, where $p$ is a partition vector and $\\alpha$ is a vector of parameters. It is also necessary to specify the largest hyperedge size under consideration. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "kmax = 4\n",
    "\n",
    "function ω(p, α)\n",
    "    k = sum(p)\n",
    "    return sum(p)/sum((p .* (1:length(p)).^α[k])) / n^(α[kmax+k]*k)\n",
    "end\n",
    "\n",
    "Ω = partitionIntensityFunction(ω, kmax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Synthetic Hypergraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an affinity function has been constructed, it may be used to sample from the DCHSBM model. It is necessary to also set a node cluster vector, a vector of degree parameters $\\vartheta$, and a value of the parameter $\\alpha$ passed to $\\Omega$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypergraph\n",
       "  N: Array{Int64}((100,)) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
       "  E: Dict{Int64,Dict}\n",
       "  D: Array{Int64}((100,)) [6, 4, 10, 11, 11, 5, 4, 11, 11, 8  …  3, 5, 3, 3, 5, 5, 8, 3, 6, 11]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = rand(1:5, n)\n",
    "ϑ = dropdims(ones(1,n) + rand(1,n), dims = 1)\n",
    "α = vcat(repeat([5.0], kmax), 0.2*(1:kmax))\n",
    "\n",
    "H = sampleSBM(Z, ϑ, Ω;α=α, kmax=kmax, kmin = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The modularity of the generated hypergraph with specified parameters is -20604.06.\n"
     ]
    }
   ],
   "source": [
    "Q = round(Float64(modularity(H, Z, Ω;α = α)), digits = 2)\n",
    "println(\"The modularity of the generated hypergraph with specified parameters is $Q.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown $\\alpha$\n",
    "\n",
    "In the inference problem, we assume that we do not know either the cluster labeling or the parameter vector $\\alpha$ (or both), and attempt to learn them from data. In this section, we'll show how to estimate the parameter $\\alpha$ from a known cluster labeling. \n",
    "\n",
    "To reiterate the limitations above, at the current time, this should only be expected to work well on relatively small hypergraphs with assortative affinity functions. \n",
    "\n",
    "#### Important Note\n",
    "\n",
    "In general, due to the normalization condition imposed on the affinity function $\\Omega$ and degree parameters $\\vartheta$ when performing inference, both the modularities and parameter estimates so obtained may vary considerably from the values obtained when generating the model. More specifically: \n",
    "\n",
    "- You won't get back the original $\\alpha$ even approximately (unless you custom-engineered $\\Omega$ to satisfy the normalization conditions). \n",
    "- The optimized modularity will not resemble the modularity calculated with the original $\\alpha$ (unless you custom-engineered $\\Omega$ to satisfy the normalization conditions). \n",
    "\n",
    "This issue reflects the fact that we impose a constraint during inference that is not imposed when generating the hypergraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 5.0\n",
       " 4.590113950118679\n",
       " 4.55105489111123\n",
       " 3.6144204657667953\n",
       " 0.5109279534173448\n",
       " 0.7478582083900334\n",
       " 0.9454931654997941\n",
       " 1.1718251467391303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α̂ = learnParameters(H, Z, Ω, α; max_iters = 100, verbose = false, tol = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The modularity of the generated hypergraph with estimated parameter α̂ is -3113.04.\n"
     ]
    }
   ],
   "source": [
    "Q = round(Float64(modularity(H, Z, Ω;α = α̂)), digits = 2)\n",
    "println(\"The modularity of the generated hypergraph with estimated parameter α̂ is $Q.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown Partition\n",
    "\n",
    "In most practical contexts, we do not know the labeling either. In this case, we can alternate between estimates of $\\hat{\\alpha}$ using `learnParameters` and estimates of the cluster labels $\\mathbf{Z}$ using one of the supplied Louvain algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current modularity -3286.79 with 100 clusters.\n",
      "Current modularity -3087.39 with 10 clusters.\n",
      "Current modularity -3078.78 with 10 clusters.\n",
      "Current modularity -3075.98 with 11 clusters.\n",
      "Current modularity -3074.54 with 11 clusters.\n",
      "Current modularity -3071.64 with 11 clusters.\n",
      "Current modularity -3072.31 with 12 clusters.\n",
      "Current modularity -3075.57 with 11 clusters.\n",
      "Current modularity -3071.17 with 11 clusters.\n",
      "Current modularity -3072.49 with 11 clusters.\n"
     ]
    }
   ],
   "source": [
    "α̂ = vcat(repeat([1.0], kmax), 0.1*(1:kmax)) # initial guess\n",
    "Ẑ = ones(n)\n",
    "\n",
    "n_rounds = 10\n",
    "\n",
    "for i ∈ 1:n_rounds\n",
    "    Ẑ = SuperNodeLouvain(H, Ω; α = α̂, verbose = false, )\n",
    "    α̂ = learnParameters(H, Ẑ, Ω, α̂; tol = 1e-8)\n",
    "    \n",
    "    Q = round(Float64(modularity(H, Ẑ, Ω;α = α̂)), digits = 2)\n",
    "    k = length(unique(Ẑ))\n",
    "    println(\"Current modularity $Q with $k clusters.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recovered a clustering of 16 clusters, when the true data set contained only 5. Despite this, our clustering is noticeably correlated with the true clusters as measured by the mutual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5610321374864219"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutualInformation(Z, Ẑ, true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
